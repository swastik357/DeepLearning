{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhWV8oes-wKR"
      },
      "source": [
        "# COURSE: A deep understanding of deep learning\n",
        "## SECTION: RNNs (and LSTM and GRU)\n",
        "### LECTURE: The LSTM and GRU classes\n",
        "#### TEACHER: Mike X Cohen, sincxpress.com\n",
        "##### COURSE URL: udemy.com/course/deeplearning_x/?couponCode=202305"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7-LiwqUMGYL"
      },
      "source": [
        "### import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxH9iWl34bmR"
      },
      "source": [
        "# Explore the LSTM type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTIEHcqz4e6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83de0630-0630-4ed2-e197-8df6d0b4c877"
      },
      "source": [
        "# set layer parameters\n",
        "input_size  =  9 # number of features to extract (e.g., number of data channels)\n",
        "hidden_size = 16 # number of units in the hidden state\n",
        "num_layers  =  2 # number of vertical stacks of hidden layers (note: only the final layer gives an output)\n",
        "\n",
        "# create an LSTM instance\n",
        "lstm = nn.LSTM(input_size,hidden_size,num_layers)\n",
        "lstm"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(9, 16, num_layers=2)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loAF6NFjX6nQ"
      },
      "source": [
        "# check out the source code for more detailed info about this class\n",
        "??nn.LSTM"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPMVY6Em5B7y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f76348e0-e592-40d4-8634-b9432fab075d"
      },
      "source": [
        "# set data parameters\n",
        "seqlength = 5\n",
        "batchsize = 2\n",
        "\n",
        "# create some data\n",
        "X = torch.rand(seqlength,batchsize,input_size)\n",
        "\n",
        "# create initial hidden states (typically initialized as zeros)\n",
        "H = torch.zeros(num_layers,batchsize,hidden_size)\n",
        "C = torch.zeros(num_layers,batchsize,hidden_size)\n",
        "\n",
        "# the input is actually a tuple of (hidden,cell)\n",
        "hiddeninputs = (H,C)\n",
        "\n",
        "# run some data through the model and show the output sizes\n",
        "y,h = lstm(X,hiddeninputs)\n",
        "print(f' Input shape: {list(X.shape)}')\n",
        "print(f'Hidden shape: {list(h[0].shape)}')\n",
        "print(f'  Cell shape: {list(h[1].shape)}')\n",
        "print(f'Output shape: {list(y.shape)}')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Input shape: [5, 2, 9]\n",
            "Hidden shape: [2, 2, 16]\n",
            "  Cell shape: [2, 2, 16]\n",
            "Output shape: [5, 2, 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NO2PlZx_R2m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "417c28a0-3fe2-4f90-d387-062470c83beb"
      },
      "source": [
        "# Check out the learned parameters and their sizes\n",
        "for p in lstm.named_parameters():\n",
        "  if 'weight' in p[0]:\n",
        "    print(f'{p[0]} has size {list(p[1].shape)}')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight_ih_l0 has size [64, 9]\n",
            "weight_hh_l0 has size [64, 16]\n",
            "weight_ih_l1 has size [64, 16]\n",
            "weight_hh_l1 has size [64, 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pFPzSU4MSGg"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VToReEHNWP0n"
      },
      "source": [
        "# Create a DL model class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVcrKOC1Wqk-"
      },
      "source": [
        "class LSTMnet(nn.Module):\n",
        "  def __init__(self,input_size,num_hidden,num_layers):\n",
        "    super().__init__()\n",
        "\n",
        "    # store parameters\n",
        "    self.input_size = input_size\n",
        "    self.num_hidden = num_hidden\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    # RNN Layer (notation: LSTM \\in RNN)\n",
        "    self.lstm = nn.LSTM(input_size,num_hidden,num_layers)\n",
        "\n",
        "    # linear layer for output\n",
        "    self.out = nn.Linear(num_hidden,1)\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    print(f'Input: {list(x.shape)}')\n",
        "\n",
        "    # run through the RNN layer\n",
        "    y,hidden = self.lstm(x)\n",
        "    print(f'RNN-out: {list(y.shape)}')\n",
        "    print(f'RNN-hidden: {list(hidden[0].shape)}')\n",
        "    print(f'RNN-cell: {list(hidden[1].shape)}')\n",
        "\n",
        "    # pass the RNN output through the linear output layer\n",
        "    o = self.out(y)\n",
        "    print(f'Output: {list(o.shape)}')\n",
        "\n",
        "    return o,hidden"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQKkLPUeWqn_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc27c30f-ffcd-413a-a299-58397a322efa"
      },
      "source": [
        "# create an instance of the model and inspect\n",
        "net = LSTMnet(input_size,hidden_size,num_layers)\n",
        "print(net), print(' ')\n",
        "\n",
        "# and check out all learnable parameters\n",
        "for p in net.named_parameters():\n",
        "  print(f'{p[0]:>20} has size {list(p[1].shape)}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTMnet(\n",
            "  (lstm): LSTM(9, 16, num_layers=2)\n",
            "  (out): Linear(in_features=16, out_features=1, bias=True)\n",
            ")\n",
            " \n",
            "   lstm.weight_ih_l0 has size [64, 9]\n",
            "   lstm.weight_hh_l0 has size [64, 16]\n",
            "     lstm.bias_ih_l0 has size [64]\n",
            "     lstm.bias_hh_l0 has size [64]\n",
            "   lstm.weight_ih_l1 has size [64, 16]\n",
            "   lstm.weight_hh_l1 has size [64, 16]\n",
            "     lstm.bias_ih_l1 has size [64]\n",
            "     lstm.bias_hh_l1 has size [64]\n",
            "          out.weight has size [1, 16]\n",
            "            out.bias has size [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WL8wjwn0Jwr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e295d1d-c366-49c9-a948-76841e672896"
      },
      "source": [
        "# test the model with some data\n",
        "# create some data\n",
        "X = torch.rand(seqlength,batchsize,input_size)\n",
        "y = torch.rand(seqlength,batchsize,1)\n",
        "yHat,h = net(X)\n",
        "\n",
        "\n",
        "lossfun = nn.MSELoss()\n",
        "lossfun(yHat,y)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: [5, 2, 9]\n",
            "RNN-out: [5, 2, 16]\n",
            "RNN-hidden: [2, 2, 16]\n",
            "RNN-cell: [2, 2, 16]\n",
            "Output: [5, 2, 1]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5481, grad_fn=<MseLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXtU8uw-_7P0"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdQ9d5UC_7Ss"
      },
      "source": [
        "# GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DclTJD17-66o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d43ddb53-20f4-4871-e8ec-c188b043ffaa"
      },
      "source": [
        "# create a GRU instance\n",
        "gru = nn.GRU(input_size,hidden_size,num_layers)\n",
        "gru"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GRU(9, 16, num_layers=2)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8irbAyPitaUI"
      },
      "source": [
        "??nn.GRU"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sg-G5f2g-69O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "477bbce9-f28f-4a69-d67b-e3338cddd1d8"
      },
      "source": [
        "# create some data and a hidden state\n",
        "X = torch.rand(seqlength,batchsize,input_size)\n",
        "H = torch.zeros(num_layers,batchsize,hidden_size)\n",
        "\n",
        "# run some data through the model and show the output sizes\n",
        "y,h = gru(X,H) # No cell states in GRU!\n",
        "print(f' Input shape: {list(X.shape)}')\n",
        "print(f'Hidden shape: {list(h.shape)}')\n",
        "print(f'Output shape: {list(y.shape)}')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Input shape: [5, 2, 9]\n",
            "Hidden shape: [2, 2, 16]\n",
            "Output shape: [5, 2, 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qd9y5lT4snEQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26475e83-36b6-4cee-cb4c-6598c86fb5ec"
      },
      "source": [
        "# Check out the learned parameters and their sizes\n",
        "for p in gru.named_parameters():\n",
        "  print(f'{p[0]:>15} has size {list(p[1].shape)}')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   weight_ih_l0 has size [48, 9]\n",
            "   weight_hh_l0 has size [48, 16]\n",
            "     bias_ih_l0 has size [48]\n",
            "     bias_hh_l0 has size [48]\n",
            "   weight_ih_l1 has size [48, 16]\n",
            "   weight_hh_l1 has size [48, 16]\n",
            "     bias_ih_l1 has size [48]\n",
            "     bias_hh_l1 has size [48]\n"
          ]
        }
      ]
    }
  ]
}